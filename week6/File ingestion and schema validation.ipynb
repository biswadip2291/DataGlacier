{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2976436978"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Size of the file\n",
    "os.path.getsize(\"C:/ads/DataGlacier/week6/LI-Medium_Trans.csv/LI-Medium_Trans.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read csv with dask:  0.009280204772949219 sec\n"
     ]
    }
   ],
   "source": [
    "from dask import dataframe as dd\n",
    "start = time.time()\n",
    "dask_df = dd.read_csv(\"C:/ads/DataGlacier/week6/LI-Medium_Trans.csv/LI-Medium_Trans.csv\")\n",
    "end = time.time()\n",
    "print(\"Read csv with dask: \",(end-start),\"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read csv with pandas:  58.559502363204956 sec\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "start = time.time()\n",
    "df = pd.read_csv(\"C:/ads/DataGlacier/week6/LI-Medium_Trans.csv/LI-Medium_Trans.csv\")\n",
    "end = time.time()\n",
    "print(\"Read csv with pandas: \",(end-start),\"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-12 21:49:46,822\tINFO worker.py:1788 -- Started a local Ray instance.\n",
      "\u001b[36m(pid=31684)\u001b[0m c:\\Users\\biswa\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "\u001b[36m(pid=31684)\u001b[0m   from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read csv with modin and ray:  54.58161640167236 sec\n"
     ]
    }
   ],
   "source": [
    "import modin.pandas as pd\n",
    "import ray\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "start = time.time()\n",
    "df = pd.read_csv(\"C:/ads/DataGlacier/week6/LI-Medium_Trans.csv/LI-Medium_Trans.csv\")\n",
    "end = time.time()\n",
    "print(\"Read csv with modin and ray: \",(end-start),\"sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here Dask is better than Pandas, Modin and Ray, with the least reading time of 0.01sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import dataframe as dd\n",
    "df = dd.read_csv(\"C:/ads/DataGlacier/week6/LI-Medium_Trans.csv/LI-Medium_Trans.csv\",delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.core.DataFrame'>\n",
      "Columns: 11 entries, Timestamp to Is Laundering\n",
      "dtypes: object(6), float64(2), int64(3)"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31251483"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#No. of Rows\n",
    "len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#No, of Columns\n",
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove special character\n",
    "df.columns=df.columns.str.replace('[#,@,&]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To remove white space from columns\n",
    "df.columns = df.columns.str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Timestamp', 'FromBank', 'Account', 'ToBank', 'Account.1',\n",
       "       'AmountReceived', 'ReceivingCurrency', 'AmountPaid', 'PaymentCurrency',\n",
       "       'PaymentFormat', 'IsLaundering'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=df.columns\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\biswa\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import subprocess\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import datetime \n",
    "import gc\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting utility.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile utility.py\n",
    "import logging\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def read_config_file(filepath):\n",
    "    with open(filepath, 'r') as stream:\n",
    "        try:\n",
    "            return yaml.safe_load(stream)\n",
    "        except yaml.YAMLError as exc:\n",
    "            logging.error(exc)\n",
    "            return None\n",
    "\n",
    "def replacer(string, char):\n",
    "    pattern = char + '{2,}'\n",
    "    string = re.sub(pattern, char, string) \n",
    "    return string\n",
    "\n",
    "def col_header_val(df, table_config):\n",
    "    '''\n",
    "    Replace whitespaces in the column and standardize column names\n",
    "    '''\n",
    "    df.columns = df.columns.str.lower()\n",
    "    df.columns = df.columns.str.replace('[^\\w]', '_', regex=True)\n",
    "    df.columns = list(map(lambda x: x.strip('_'), list(df.columns)))\n",
    "    df.columns = list(map(lambda x: replacer(x, '_'), list(df.columns)))\n",
    "    expected_col = list(map(lambda x: x.lower(), table_config['columns']))\n",
    "    expected_col.sort()\n",
    "    df.columns = list(map(lambda x: x.lower(), list(df.columns)))\n",
    "    df = df.reindex(sorted(df.columns), axis=1)\n",
    "    if len(df.columns) == len(expected_col) and list(expected_col) == list(df.columns):\n",
    "        print(\"Column name and column length validation passed\")\n",
    "        return 1\n",
    "    else:\n",
    "        print(\"Column name and column length validation failed\")\n",
    "        mismatched_columns_file = list(set(df.columns).difference(expected_col))\n",
    "        print(\"Following file columns are not in the YAML file\", mismatched_columns_file)\n",
    "        missing_YAML_file = list(set(expected_col).difference(df.columns))\n",
    "        print(\"Following YAML columns are not in the file uploaded\", missing_YAML_file)\n",
    "        logging.info(f'DF columns: {df.columns}')\n",
    "        logging.info(f'Expected columns: {expected_col}')\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting file.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile file.yaml\n",
    "file_type: csv\n",
    "dataset_name: file\n",
    "file_name: LI-Medium_Trans\n",
    "table_name: edsurv\n",
    "inbound_delimiter: \",\"\n",
    "outbound_delimiter: \"|\"\n",
    "skip_leading_rows: 1\n",
    "columns: \n",
    "   - Timestamp\n",
    "   - From Bank\n",
    "   - Account\n",
    "   - To Bank\n",
    "   - Account.1\n",
    "   - Amount Received\n",
    "   - Receiving Currency\n",
    "   - Amount Paid\n",
    "   - Payment Currency\n",
    "   - Payment Format\n",
    "   - Is Laundering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_type': 'csv',\n",
       " 'dataset_name': 'file',\n",
       " 'file_name': 'LI-Medium_Trans',\n",
       " 'table_name': 'edsurv',\n",
       " 'inbound_delimiter': ',',\n",
       " 'outbound_delimiter': '|',\n",
       " 'skip_leading_rows': 1,\n",
       " 'columns': ['Timestamp',\n",
       "  'From Bank',\n",
       "  'Account',\n",
       "  'To Bank',\n",
       "  'Account.1',\n",
       "  'Amount Received',\n",
       "  'Receiving Currency',\n",
       "  'Amount Paid',\n",
       "  'Payment Currency',\n",
       "  'Payment Format',\n",
       "  'Is Laundering']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading config file\n",
    "\n",
    "import utility as util\n",
    "config_data = util.read_config_file(\"file.yaml\")\n",
    "config_data\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'csv'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_data['file_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "','"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_data['inbound_delimiter']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the file using config file\n",
    "file_type = config_data['file_type']\n",
    "source_file = \"C:/ads/DataGlacier/week6/LI-Medium_Trans.csv/\" + config_data['file_name'] + f'.{file_type}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "','"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_data['inbound_delimiter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>From Bank</th>\n",
       "      <th>Account</th>\n",
       "      <th>To Bank</th>\n",
       "      <th>Account.1</th>\n",
       "      <th>Amount Received</th>\n",
       "      <th>Receiving Currency</th>\n",
       "      <th>Amount Paid</th>\n",
       "      <th>Payment Currency</th>\n",
       "      <th>Payment Format</th>\n",
       "      <th>Is Laundering</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022/09/01 00:15</td>\n",
       "      <td>20</td>\n",
       "      <td>800104D70</td>\n",
       "      <td>20</td>\n",
       "      <td>800104D70</td>\n",
       "      <td>8095.07</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>8095.07</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022/09/01 00:18</td>\n",
       "      <td>3196</td>\n",
       "      <td>800107150</td>\n",
       "      <td>3196</td>\n",
       "      <td>800107150</td>\n",
       "      <td>7739.29</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>7739.29</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022/09/01 00:23</td>\n",
       "      <td>1208</td>\n",
       "      <td>80010E430</td>\n",
       "      <td>1208</td>\n",
       "      <td>80010E430</td>\n",
       "      <td>2654.22</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>2654.22</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022/09/01 00:19</td>\n",
       "      <td>3203</td>\n",
       "      <td>80010EA80</td>\n",
       "      <td>3203</td>\n",
       "      <td>80010EA80</td>\n",
       "      <td>13284.41</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>13284.41</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022/09/01 00:27</td>\n",
       "      <td>20</td>\n",
       "      <td>800104D20</td>\n",
       "      <td>20</td>\n",
       "      <td>800104D20</td>\n",
       "      <td>9.72</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>9.72</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Timestamp  From Bank    Account  To Bank  Account.1  \\\n",
       "0  2022/09/01 00:15         20  800104D70       20  800104D70   \n",
       "1  2022/09/01 00:18       3196  800107150     3196  800107150   \n",
       "2  2022/09/01 00:23       1208  80010E430     1208  80010E430   \n",
       "3  2022/09/01 00:19       3203  80010EA80     3203  80010EA80   \n",
       "4  2022/09/01 00:27         20  800104D20       20  800104D20   \n",
       "\n",
       "   Amount Received Receiving Currency  Amount Paid Payment Currency  \\\n",
       "0          8095.07          US Dollar      8095.07        US Dollar   \n",
       "1          7739.29          US Dollar      7739.29        US Dollar   \n",
       "2          2654.22          US Dollar      2654.22        US Dollar   \n",
       "3         13284.41          US Dollar     13284.41        US Dollar   \n",
       "4             9.72          US Dollar         9.72        US Dollar   \n",
       "\n",
       "  Payment Format  Is Laundering  \n",
       "0   Reinvestment              0  \n",
       "1   Reinvestment              0  \n",
       "2   Reinvestment              0  \n",
       "3   Reinvestment              0  \n",
       "4   Reinvestment              0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(source_file,delimiter=config_data['inbound_delimiter'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column name and column length validation failed\n",
      "Following file columns are not in the YAML file ['account_1', 'amount_paid', 'amount_received', 'from_bank', 'payment_format', 'receiving_currency', 'is_laundering', 'payment_currency', 'to_bank']\n",
      "Following YAML columns are not in the file uploaded ['from bank', 'account.1', 'amount received', 'receiving currency', 'to bank', 'payment format', 'payment currency', 'amount paid', 'is laundering']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validating the header of the file\n",
    "util.col_header_val(df,config_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column name and column length validation failed\n",
      "Following file columns are not in the YAML file ['account_1', 'amount_paid', 'amount_received', 'from_bank', 'payment_format', 'receiving_currency', 'is_laundering', 'payment_currency', 'to_bank']\n",
      "Following YAML columns are not in the file uploaded ['from bank', 'account.1', 'amount received', 'receiving currency', 'to bank', 'payment format', 'payment currency', 'amount paid', 'is laundering']\n",
      "validation failed\n"
     ]
    }
   ],
   "source": [
    "if util.col_header_val(df,config_data)==0:\n",
    "    print(\"validation failed\")\n",
    "else:\n",
    "    print(\"col validation passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\00.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\01.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\02.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\03.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\04.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\05.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\06.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\07.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\08.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\09.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\10.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\11.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\12.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\13.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\14.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\15.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\16.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\17.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\18.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\19.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\20.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\21.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\22.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\23.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\24.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\25.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\26.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\27.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\28.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\29.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\30.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\31.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\32.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\33.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\34.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\35.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\36.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\37.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\38.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\39.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\40.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\41.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\42.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\43.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\44.part',\n",
       " 'c:\\\\ads\\\\DataGlacier\\\\week6\\\\LI-Medium_Trans.csv.gz\\\\45.part']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import gzip\n",
    "\n",
    "from dask import dataframe as dd\n",
    "df = dd.read_csv('C:/ads/DataGlacier/week6/LI-Medium_Trans.csv/LI-Medium_Trans.csv', delimiter=\",\")\n",
    "\n",
    "# Write csv in gz format in pipe separated text file (|)\n",
    "df.to_csv('LI-Medium_Trans.csv.gz',\n",
    "          sep='|',\n",
    "          header=True,\n",
    "          index=False,\n",
    "          quoting=csv.QUOTE_ALL,\n",
    "          compression='gzip',\n",
    "          quotechar='\"',\n",
    "          doublequote=True\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File summary:\n",
      "Number of rows: 31251483\n",
      "Number of columns: 11\n",
      "File size: 16384 bytes\n"
     ]
    }
   ],
   "source": [
    "# Get file summary\n",
    "file_size = os.path.getsize('LI-Medium_Trans.csv.gz')\n",
    "num_rows = len(df)\n",
    "num_cols = len(df.columns)\n",
    "\n",
    "# Print file summary\n",
    "print(\"File summary:\")\n",
    "print(f\"Number of rows: {num_rows}\")\n",
    "print(f\"Number of columns: {num_cols}\")\n",
    "print(f\"File size: {file_size} bytes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
